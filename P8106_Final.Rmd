---
title: "Final Project"
author: "Zhezheng Jin"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
editor_options: 
  chunk_output_type: console
--- 

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
```

```{r, echo = TRUE, message = FALSE, results='hide', warning=FALSE}
library(caret)
library(MASS)
library(mlbench)
library(pROC)
library(klaR)
library(glmnet)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(tidyverse)
library(summarytools)
library(corrplot)
library(plotmo)
library(viridis)
library(gtsummary)
library(e1071)
library(tidymodels)
library(patchwork)
library(kernlab)
library(doParallel)
```

## Data Import and Wrangling
```{r}
load("severity_training.RData")
load("severity_test.RData")

skimr::skim(test_data)
skimr::skim(training_data)
# In total, 7 factor variables in the data

train <- training_data %>%
  janitor::clean_names() %>%
  select(-id) %>%
  select(age,height,weight,bmi,sbp,ldl,everything()) %>%
  mutate(
    gender = factor(gender,levels = c("0","1"), labels = c("Female", "Male")),
    race = factor(race,levels = c("1","2","3","4"),
                  labels = c("White", "Asian","Black","Hispanic")),
    smoking = factor(smoking,levels = c("0","1","2"),
                     labels = c("Never_smoked", "Former_smoker","Current_smoker")),
    hypertension = factor(hypertension,levels = c("0", "1"),
                          labels = c("No", "Yes")),
    diabetes = factor(diabetes,levels = c("0", "1"),
                      labels = c("No", "Yes")),
    vaccine = factor(vaccine,levels = c("0", "1"),
                     labels = c("Not_vaccinated", "Vaccinated")),
    severity = factor(severity,levels = c("0", "1"),
                      labels = c("not_severe", "severe"))
      )
test <- test_data %>%
  janitor::clean_names() %>%
  select(-id) %>%
  mutate(
    gender = factor(gender,levels = c("0","1"), labels = c("Female", "Male")),
    race = factor(race,levels = c("1","2","3","4"),
                  labels = c("White", "Asian","Black","Hispanic")),
    smoking = factor(smoking,levels = c("0","1","2"),
                     labels = c("Never_smoked", "Former_smoker","Current_smoker")),
    hypertension = factor(hypertension,levels = c("0", "1"),
                          labels = c("No", "Yes")),
    diabetes = factor(diabetes,levels = c("0", "1"),
                      labels = c("No", "Yes")),
    vaccine = factor(vaccine,levels = c("0", "1"),
                     labels = c("Not_vaccinated", "Vaccinated")),
    severity = factor(severity,levels = c("0", "1"),
                      labels = c("not_severe", "severe"))
      )
```

## EDA

We will use training data for EDA.

### Outcome:severity
```{r}
# Bar chart
y_bar <- train %>%
  ggplot(aes(x = severity, fill = severity)) + 
  geom_bar(stat = "Count", position = "dodge", alpha = 0.8) +
  labs(x = "severity", fill = "severity",title = "Bar Chart of Severity of COVID-19
       infection") + 
  geom_text(stat = "Count", aes(label = after_stat(count), group = severity),
            position = position_dodge(width = 0.9), vjust = -0.5,size = 3,fontface = "bold") +
  theme(
        legend.position = "bottom",
        plot.title = element_text(face = "bold",hjust = 0.5)
       )

y_bar
```


### Numerical Predictors
```{r}
skimr::skim(train)

# Multicollinearity

corrplot(cor(train[, 1:6]), method = "circle", type = "full")

# Multicollinearity presents.

# Density Plots
theme1 <- transparentTheme(trans = .8)
trellis.par.set(theme1)

density <- featurePlot(x = train[, 1:6],
                       y = train$severity,
                       scales = list(x = list(relation = "free"),
                                     y = list(relation = "free")),
                       plot = "density", pch = "|",
                       auto.key = list(columns = 2),
                       labels = c("value","density"),
                       main = "Density Plots of Numerical Predictors by Severity 
of COVID-19 infection")
density
```

### Categorical Predictors
```{r}
# Bar Chart
gender_bar <- train %>%
  ggplot(aes(x = gender, fill = severity)) + 
  geom_bar(stat = "count", position = "dodge", alpha = 0.8) +
  labs(x = "Gender", fill = "Severity of COVID-19 infection") +
  theme_minimal() +
  theme(legend.position = "bottom")

race_bar <- train %>%
  ggplot(aes(x = race, fill = severity)) + 
  geom_bar(stat = "count", position = "dodge", alpha = 0.8) +
  labs(x = "Race", fill = "Severity of COVID-19 infection") +
  theme_minimal() +
  theme(legend.position = "bottom") 

smoking_bar <- train %>%
  ggplot(aes(x = smoking, fill = severity)) + 
  geom_bar(stat = "count", position = "dodge", alpha = 0.8) +
  labs(x = "Smoking", fill = "Severity of COVID-19 infection") +
  theme_minimal() +
  theme(legend.position = "bottom") 

diabetes_bar <- train %>%
  ggplot(aes(x = diabetes, fill = severity)) + 
  geom_bar(stat = "count", position = "dodge", alpha = 0.8) +
  labs(x = "Diabetes", fill = "Severity of COVID-19 infection") +
  theme_minimal() +
  theme(legend.position = "bottom") 
      
hypertension_bar <- train %>%
  ggplot(aes(x = hypertension, fill = severity)) + 
  geom_bar(stat = "count", position = "dodge", alpha = 0.8) +
  labs(x = "Hypertension", fill = "Severity of COVID-19 infection") +
  theme_minimal() +
  theme(legend.position = "bottom") 

vaccine_bar <- train %>%
  ggplot(aes(x = vaccine, fill = severity)) + 
  geom_bar(stat = "count", position = "dodge", alpha = 0.8) +
  labs(x = "Vaccine", fill = "Severity of COVID-19 infection") +
  theme_minimal() +
  theme(legend.position = "bottom") 

cate.bar <- gender_bar + race_bar + smoking_bar + 
  diabetes_bar + hypertension_bar + vaccine_bar +
  plot_layout(ncol = 2) + 
  plot_annotation(title = "Bar Charts of Severity of COVID-19 Infection 
by Categorical Predictors")
cate.bar + plot_layout(guides = 'collect') & 
  theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5))
```

## Model Training

Using caret

### Penalized Logistic Regression
```{r}
registerDoParallel(detectCores() - 1)
ctrl <- trainControl(method = "cv", number = 10,
                     allowParallel = TRUE)

glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 21),
                        .lambda = exp(seq(-6, 3, length = 50)))

set.seed(2358)
glmn.fit <- train(severity ~ .,
                 data = train,
                 method = "glmnet",
                 tuneGrid = glmnGrid,
                 trControl = ctrl)
glmn.fit$bestTune # within the range

# Performance Evaluation
glmn.pred.prob <- predict(glmn.fit, newdata = test,type = "prob") [,2]
glmn.pred <- rep("not_severe", length(glmn.pred.prob))
glmn.pred[glmn.pred.prob>0.5] <- "severe"

confusionMatrix(data = as.factor(glmn.pred),
                reference = test$severity,
                positive = "severe")

coef(glmn.fit$finalModel, s = glmn.fit$bestTune$lambda)

vip(glmn.fit$finalModel)
```

### MARS
```{r}
set.seed(2358)
mars.fit <- train(severity ~ .,
                    data = train,
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:3, 
                                           nprune = 2:25),
                    trControl = ctrl)

ggplot(mars.fit, highlight = TRUE)

# Performance Evaluation
mars.pred <- predict(mars.fit, newdata = test)

confusionMatrix(data = as.factor(mars.pred),
                reference = test$severity,
                positive = "severe")
```


### SVM-Radial Kernel
```{r}
svmr.grid <- expand.grid(C = exp(seq(-2,6,len=50)),
                         sigma = exp(seq(-6,-2,len=20)))
set.seed(2358)
svmr.fit <- train(severity ~ ., 
                  data = train,
                  method = "svmRadialSigma",
                  tuneGrid = svmr.grid,
                  trControl = ctrl)

plot(svmr.fit, transform.y = log, transform.x = log, 
     color.palette = terrain.colors)

# Performance Evaluation
svmr.pred <- predict(svmr.fit, newdata = test)

confusionMatrix(data = as.factor(svmr.pred),
                reference = test$severity,
                positive = "severe")
```

### Random Forest
```{r}
rf.grid <- expand.grid(mtry = 1:13,
                       splitrule = "gini",
                       min.node.size = 1:6)
set.seed(2358)
rf.fit <- train(severity ~ ., 
                  data = train,
                  method = "ranger",
                  tuneGrid = rf.grid,
                  trControl = ctrl)

ggplot(rf.fit, highlight = TRUE)

# Performance Evaluation
rf.pred <- predict(rf.fit, newdata = test)

confusionMatrix(data = as.factor(rf.pred),
                reference = test$severity,
                positive = "severe")
```

### Classification Tree(Adaboost)
```{r}
gbmA.grid <- expand.grid(n.trees = c(2000,3000,4000,5000),
                         interaction.depth = 1:10,
                         shrinkage = c(0.001,0.002,0.003),
                         n.minobsinnode = 1)
set.seed(2358)
gbmA.fit <- train(severity ~ .,
                  data = train,
                  method = "gbm",
                  tuneGrid = gbmA.grid,
                  trControl = ctrl,
                  distribution = "adaboost",
                  verbose = FALSE)

ggplot(gbmA.fit, highlight = TRUE)

# Variable importance
summary(gbmA.fit$finalModel, las = 2, cBars = 7, cex.names = 0.6)

# Performance Evaluation
gbmA.pred <- predict(gbmA.fit, newdata = test)

confusionMatrix(data = as.factor(gbmA.pred),
                reference = test$severity,
                positive = "severe")
```

### Comparison
```{r}
res <- resamples(
  list(
    Glm_net = glmn.fit,
    MARS = mars.fit, 
    SVM_Radial = svmr.fit,
    Random_Forest = rf.fit,
    CT_Adaboost = gbmA.fit
    ))
summary(res)

bwplot(res, metric="Accuracy")

res$values %>% 
  dplyr::select(1, ends_with("Accuracy")) %>%
  gather(model, Accuracy, -1) %>% 
  mutate(model = sub("~Accuracy", "", model)) %>% 
  ggplot() + 
  geom_boxplot(aes(x = Accuracy, y = model)) +
  labs(x = "CV Accuracy", y = "Models")
```

